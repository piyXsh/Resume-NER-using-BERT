{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval==0.0.12\r\n",
      "  Downloading seqeval-0.0.12.tar.gz (21 kB)\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval==0.0.12) (1.18.2)\r\n",
      "Requirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.6/site-packages (from seqeval==0.0.12) (2.3.1)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.14.0)\r\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.4.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12) (2.10.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12) (5.3.1)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.0.8)\r\n",
      "Building wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7423 sha256=713e987387b00afe6189385a02d63e085f5897410e813524adcba85a032e863c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/1b/a6/a808a7e4d1f7584e42f5e279664cd48bf24ed8392218ce6be4\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: seqeval\r\n",
      "Successfully installed seqeval-0.0.12\r\n"
     ]
    }
   ],
   "source": [
    "# Required Library\n",
    "!pip install seqeval==0.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing required Libraries\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from seqeval.metrics import f1_score\n",
    "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm,trange\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import re\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_address = \"../input/resume-entities-for-ner//Entity Recognition in Resumes.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek Jha\\nApplication Development Associat...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n",
       "      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n",
       "      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anvitha Rao\\nAutomation developer\\n\\n- Email m...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 28...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arjun ks\\nSenior Program coordinator - oracle ...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 34...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arun Elumalai\\nQA Tester\\n\\nChennai, Tamil Nad...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 19...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ashalata Bisoyi\\nTransaction Processor - Oracl...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 17...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ashok Kunam\\nTeam Lead - Microsoft\\n\\n- Email ...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 41...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Abhishek Jha\\nApplication Development Associat...   \n",
       "1  Afreen Jamadar\\nActive member of IIIT Committe...   \n",
       "2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n",
       "3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n",
       "4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n",
       "5  Anvitha Rao\\nAutomation developer\\n\\n- Email m...   \n",
       "6  arjun ks\\nSenior Program coordinator - oracle ...   \n",
       "7  Arun Elumalai\\nQA Tester\\n\\nChennai, Tamil Nad...   \n",
       "8  Ashalata Bisoyi\\nTransaction Processor - Oracl...   \n",
       "9  Ashok Kunam\\nTeam Lead - Microsoft\\n\\n- Email ...   \n",
       "\n",
       "                                          annotation  extras  \n",
       "0  [{'label': ['Skills'], 'points': [{'start': 12...     NaN  \n",
       "1  [{'label': ['Email Address'], 'points': [{'sta...     NaN  \n",
       "2  [{'label': ['Skills'], 'points': [{'start': 37...     NaN  \n",
       "3  [{'label': ['Skills'], 'points': [{'start': 80...     NaN  \n",
       "4  [{'label': ['Degree'], 'points': [{'start': 20...     NaN  \n",
       "5  [{'label': ['Skills'], 'points': [{'start': 28...     NaN  \n",
       "6  [{'label': ['Skills'], 'points': [{'start': 34...     NaN  \n",
       "7  [{'label': ['Skills'], 'points': [{'start': 19...     NaN  \n",
       "8  [{'label': ['Skills'], 'points': [{'start': 17...     NaN  \n",
       "9  [{'label': ['Skills'], 'points': [{'start': 41...     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "df_data = pd.read_json(data_file_address, lines=True)\n",
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation</th>\n",
       "      <th>extras</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abhishek Jha Application Development Associate...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afreen Jamadar Active member of IIIT Committee...</td>\n",
       "      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akhil Yadav Polemaina Hyderabad, Telangana - E...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alok Khandai Operational Analyst (SQL DBA) Eng...</td>\n",
       "      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ananya Chavan lecturer - oracle tutorials  Mum...</td>\n",
       "      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  Abhishek Jha Application Development Associate...   \n",
       "1  Afreen Jamadar Active member of IIIT Committee...   \n",
       "2  Akhil Yadav Polemaina Hyderabad, Telangana - E...   \n",
       "3  Alok Khandai Operational Analyst (SQL DBA) Eng...   \n",
       "4  Ananya Chavan lecturer - oracle tutorials  Mum...   \n",
       "\n",
       "                                          annotation  extras  \n",
       "0  [{'label': ['Skills'], 'points': [{'start': 12...     NaN  \n",
       "1  [{'label': ['Email Address'], 'points': [{'sta...     NaN  \n",
       "2  [{'label': ['Skills'], 'points': [{'start': 37...     NaN  \n",
       "3  [{'label': ['Skills'], 'points': [{'start': 80...     NaN  \n",
       "4  [{'label': ['Degree'], 'points': [{'start': 20...     NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing New Line characters\n",
    "for i in range(len(df_data)):\n",
    "    df_data[\"content\"][i] = df_data[\"content\"][i].replace(\"\\n\", \" \")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON formatting functions\n",
    "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
    "    try:\n",
    "        training_data = []\n",
    "        lines=[]\n",
    "        with open(dataturks_JSON_FilePath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            data = json.loads(line)\n",
    "            text = data['content'].replace(\"\\n\", \" \")\n",
    "            entities = []\n",
    "            data_annotations = data['annotation']\n",
    "            if data_annotations is not None:\n",
    "                for annotation in data_annotations:\n",
    "                    #only a single point in text annotation.\n",
    "                    point = annotation['points'][0]\n",
    "                    labels = annotation['label']\n",
    "                    # handle both list of labels or a single label.\n",
    "                    if not isinstance(labels, list):\n",
    "                        labels = [labels]\n",
    "\n",
    "                    for label in labels:\n",
    "                        point_start = point['start']\n",
    "                        point_end = point['end']\n",
    "                        point_text = point['text']\n",
    "                        \n",
    "                        lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
    "                        rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
    "                        if lstrip_diff != 0:\n",
    "                            point_start = point_start + lstrip_diff\n",
    "                        if rstrip_diff != 0:\n",
    "                            point_end = point_end - rstrip_diff\n",
    "                        entities.append((point_start, point_end + 1 , label))\n",
    "            training_data.append((text, {\"entities\" : entities}))\n",
    "        return training_data\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n",
    "        return None\n",
    "\n",
    "def trim_entity_spans(data: list) -> list:\n",
    "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
    "\n",
    "    Args:\n",
    "        data (list): The data to be cleaned in spaCy JSON format.\n",
    "\n",
    "    Returns:\n",
    "        list: The cleaned data.\n",
    "    \"\"\"\n",
    "    invalid_span_tokens = re.compile(r'\\s')\n",
    "\n",
    "    cleaned_data = []\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                    text[valid_start]):\n",
    "                valid_start += 1\n",
    "            while valid_end > 1 and invalid_span_tokens.match(\n",
    "                    text[valid_end - 1]):\n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "        cleaned_data.append([text, {'entities': valid_entities}])\n",
    "    return cleaned_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\",\n",
       " {'entities': [[1296, 1622, 'Skills'],\n",
       "   [993, 1154, 'Skills'],\n",
       "   [939, 957, 'College Name'],\n",
       "   [883, 905, 'College Name'],\n",
       "   [856, 860, 'Graduation Year'],\n",
       "   [771, 814, 'College Name'],\n",
       "   [727, 769, 'Designation'],\n",
       "   [407, 416, 'Companies worked at'],\n",
       "   [372, 405, 'Designation'],\n",
       "   [95, 145, 'Email Address'],\n",
       "   [60, 69, 'Location'],\n",
       "   [49, 58, 'Companies worked at'],\n",
       "   [13, 46, 'Designation'],\n",
       "   [0, 12, 'Name']]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trim_entity_spans(convert_dataturks_to_spacy(data_file_address))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063036def71e4db88da81836e82330f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=220.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Changing data to appropriate format so as to feed it to the model\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "cleanedDF = pd.DataFrame(columns=[\"setences_cleaned\"])\n",
    "sum1 = 0\n",
    "for i in tqdm(range(len(data))):\n",
    "    start = 0\n",
    "    emptyList = [\"Empty\"] * len(data[i][0].split())\n",
    "    numberOfWords = 0\n",
    "    lenOfString = len(data[i][0])\n",
    "    strData = data[i][0]\n",
    "    strDictData = data[i][1]\n",
    "    lastIndexOfSpace = strData.rfind(' ')\n",
    "    for i in range(lenOfString):\n",
    "        if (strData[i]==\" \" and strData[i+1]!=\" \"):\n",
    "            for k,v in strDictData.items():\n",
    "                for j in range(len(v)):\n",
    "                    entList = v[len(v)-j-1]\n",
    "                    if (start>=int(entList[0]) and i<=int(entList[1])):\n",
    "                        emptyList[numberOfWords] = entList[2]\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "            start = i + 1  \n",
    "            numberOfWords += 1\n",
    "        if (i == lastIndexOfSpace):\n",
    "            for j in range(len(v)):\n",
    "                    entList = v[len(v)-j-1]\n",
    "                    if (lastIndexOfSpace>=int(entList[0]) and lenOfString<=int(entList[1])):\n",
    "                        emptyList[numberOfWords] = entList[2]\n",
    "                        numberOfWords += 1\n",
    "    cleanedDF = cleanedDF.append(pd.Series([emptyList],  index=cleanedDF.columns ), ignore_index=True )\n",
    "    sum1 = sum1 + numberOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setences_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Name, Name, Designation, Designation, Designa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Name, Name, Empty, Empty, Empty, Empty, Empty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Name, Name, Name, Empty, Empty, Empty, Empty,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Name, Name, Designation, Designation, Designa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Name, Name, Designation, Empty, Companies wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    setences_cleaned\n",
       "0  [Name, Name, Designation, Designation, Designa...\n",
       "1  [Name, Name, Empty, Empty, Empty, Empty, Empty...\n",
       "2  [Name, Name, Name, Empty, Empty, Empty, Empty,...\n",
       "3  [Name, Name, Designation, Designation, Designa...\n",
       "4  [Name, Name, Designation, Empty, Companies wor..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "totalNumWords = [len(one_comment.split()) for one_comment in df_data[\"content\"]]\n",
    "plt.hist(totalNumWords)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 300\n",
    "bs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(df_data[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3331, 3332, 37, 52, 302, 517, 150, 72, 62, 59, 8, 11, 11, 13, 17, 3331, 3332, 4387, 2, 4, 23, 7, 88, 193, 105, 603, 59, 3, 890, 4, 814, 120, 20, 1, 58, 7, 120, 843, 1, 2736, 448, 5, 341, 1354, 2079, 190, 4, 198, 4, 154, 72, 23, 16, 37, 52, 302, 517, 320, 111, 4, 91, 163, 534, 76, 8, 1733, 2737, 289, 1891, 39, 1734, 449, 7, 3, 2737, 105, 244, 139, 3333, 97, 8, 481, 1355, 221, 130, 3, 2737, 7, 172, 1354, 6000, 408, 786, 1, 3334, 105, 244, 139, 481, 15, 1355, 41, 3, 128, 63, 143, 234, 5, 54, 241, 1, 145, 143, 535, 143, 159, 6, 145, 1, 78, 3335, 72, 257, 110, 4, 131, 111, 2738, 5, 2739, 6001, 3336, 202, 283, 175, 4, 290, 110, 2381, 6002, 6003, 283, 1263, 4, 290, 175, 20, 73, 67, 56, 24, 33, 83, 67, 56, 24, 33, 83, 12, 67, 56, 24, 33, 83, 12, 44, 67, 56, 24, 33, 81, 67, 56, 24, 33, 100, 54, 45, 20, 32, 34, 11, 13, 17, 3331, 3332, 4387, 47, 48, 14, 49, 14, 43, 35, 5, 2, 267, 329, 73, 73, 81, 2, 39, 1734, 2, 815, 6, 2382, 2, 891, 426, 2, 83, 12, 44, 2, 170, 1086, 2, 192, 44, 66, 8, 188, 71, 1356, 671, 45, 20, 2, 2383, 1, 892, 76, 2, 6004, 1, 965, 4, 172, 1087, 2, 6005, 1, 4388, 2, 19, 518]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = tokenizer.texts_to_sequences(df_data[\"content\"])\n",
    "# tokenized_texts = [tokenizer.tokenize(sent) for sent in df_data[\"content\"]]\n",
    "print(tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(tokenized_texts,\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vals = [\"UNKNOWN\", \"Name\", \"Degree\",\"Skills\",\"College Name\",\"Email Address\",\"Designation\",\"Companies worked at\",\"Empty\",\"Graduation Year\",\"Years of Experience\",\"Location\"]\n",
    "tag2idx = {t: i for i, t in enumerate(tags_vals)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cleanedDF[\"setences_cleaned\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Degree', 'College Name', 'Companies worked at', 'Name', 'Empty', 'Years of Experience', 'UNKNOWN', 'Skills', 'Designation'}\n"
     ]
    }
   ],
   "source": [
    "print(set(labels[61]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
    "                     maxlen=MAX_LEN, value=tag2idx[\"Empty\"], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:12<00:00, 33102856.13B/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8511637701438024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [00:08<00:34,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5098541527986526\n",
      "Validation Accuracy: 0.9231944444444444\n",
      "F1-Score: 0.9242331288343558\n",
      "Train loss: 0.5241081989728488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [00:16<00:25,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.4943576753139496\n",
      "Validation Accuracy: 0.9231944444444444\n",
      "F1-Score: 0.9242331288343558\n",
      "Train loss: 0.5169478012965276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [00:24<00:16,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.515742152929306\n",
      "Validation Accuracy: 0.9231944444444444\n",
      "F1-Score: 0.9242331288343558\n",
      "Train loss: 0.5097572069901687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [00:32<00:08,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.48067526519298553\n",
      "Validation Accuracy: 0.9231944444444444\n",
      "F1-Score: 0.9242331288343558\n",
      "Train loss: 0.484199753174415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [00:40<00:00,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5480965077877045\n",
      "Validation Accuracy: 0.9231944444444444\n",
      "F1-Score: 0.9242331288343558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "063036def71e4db88da81836e82330f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d96690626c88477786d00129e19009f5",
        "IPY_MODEL_1e90a177181745faa6ae93ab911dbba7"
       ],
       "layout": "IPY_MODEL_7f5fa98d977f4580aee0b1fb88adfb96"
      }
     },
     "1e90a177181745faa6ae93ab911dbba7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b50024d575314dcaaee8da87bcfca455",
       "placeholder": "​",
       "style": "IPY_MODEL_cab262fbc2744fbdaa90f349c21b7283",
       "value": " 220/220 [00:03&lt;00:00, 72.75it/s]"
      }
     },
     "2be9d42b5f44440fb26846d277a469ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "7f5fa98d977f4580aee0b1fb88adfb96": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b50024d575314dcaaee8da87bcfca455": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cab262fbc2744fbdaa90f349c21b7283": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d96690626c88477786d00129e19009f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e7d15119e6644c3f8d25c02175e72a7d",
       "max": 220,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2be9d42b5f44440fb26846d277a469ad",
       "value": 220
      }
     },
     "e7d15119e6644c3f8d25c02175e72a7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"cells":[{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install --no-deps seqeval[gpu]","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting seqeval[gpu]\n  Downloading seqeval-0.0.12.tar.gz (21 kB)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7423 sha256=a4b9ffe7e96e925255a03c383a53443c4229664228b110aa4c2c38e861e53405\n  Stored in directory: /root/.cache/pip/wheels/1f/1b/a6/a808a7e4d1f7584e42f5e279664cd48bf24ed8392218ce6be4\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-0.0.12\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%who","execution_count":85,"outputs":[{"output_type":"stream","text":"Interactive namespace is empty.\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport spacy\nfrom spacy.gold import biluo_tags_from_offsets\nnlp = spacy.load(\"en_core_web_lg\")\n\nfrom tqdm import trange\nimport torch\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_pretrained_bert import BertTokenizer, BertConfig\nfrom pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n\nfrom seqeval.metrics import classification_report, accuracy_score, f1_score","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding '\\n' to the default spacy tokenizer\n\nprefixes = ('\\\\n', ) + nlp.Defaults.prefixes\nprefix_regex = spacy.util.compile_prefix_regex(prefixes)\nnlp.tokenizer.prefix_search = prefix_regex.search","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Personal Custom Tags Dictionary\nentity_dict = {\n    'Name': 'NAME', \n    'College Name': 'CLG',\n    'Degree': 'DEG',\n    'Graduation Year': 'GRADYEAR',\n    'Years of Experience': 'YOE',\n    'Companies worked at': 'COMPANY',\n    'Designation': 'DESIG',\n    'Skills': 'SKILLS',\n    'Location': 'LOC',\n    'Email Address': 'EMAIL'\n}","execution_count":88,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# loading the dataset\ndf = pd.read_json('/kaggle/input/resume-entities-for-ner/Entity Recognition in Resumes.json', lines=True)\ndf.head()","execution_count":89,"outputs":[{"output_type":"execute_result","execution_count":89,"data":{"text/plain":"                                             content  \\\n0  Abhishek Jha\\nApplication Development Associat...   \n1  Afreen Jamadar\\nActive member of IIIT Committe...   \n2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n\n                                          annotation  extras  \n0  [{'label': ['Skills'], 'points': [{'start': 12...     NaN  \n1  [{'label': ['Email Address'], 'points': [{'sta...     NaN  \n2  [{'label': ['Skills'], 'points': [{'start': 37...     NaN  \n3  [{'label': ['Skills'], 'points': [{'start': 80...     NaN  \n4  [{'label': ['Degree'], 'points': [{'start': 20...     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>annotation</th>\n      <th>extras</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abhishek Jha\\nApplication Development Associat...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for unique values present in 'extras' column\ndf['extras'].unique()","execution_count":90,"outputs":[{"output_type":"execute_result","execution_count":90,"data":{"text/plain":"array([nan])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since, 'extras' column contains no information we can drop the column\ndf = df.drop(['extras'], axis=1)\ndf.head()","execution_count":91,"outputs":[{"output_type":"execute_result","execution_count":91,"data":{"text/plain":"                                             content  \\\n0  Abhishek Jha\\nApplication Development Associat...   \n1  Afreen Jamadar\\nActive member of IIIT Committe...   \n2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n\n                                          annotation  \n0  [{'label': ['Skills'], 'points': [{'start': 12...  \n1  [{'label': ['Email Address'], 'points': [{'sta...  \n2  [{'label': ['Skills'], 'points': [{'start': 37...  \n3  [{'label': ['Skills'], 'points': [{'start': 80...  \n4  [{'label': ['Degree'], 'points': [{'start': 20...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>annotation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abhishek Jha\\nApplication Development Associat...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mergeIntervals(intervals):\n    sorted_by_lower_bound = sorted(intervals, key=lambda tup: tup[0])\n    merged = []\n\n    for higher in sorted_by_lower_bound:\n        if not merged:\n            merged.append(higher)\n        else:\n            lower = merged[-1]\n            if higher[0] <= lower[1]:\n                if lower[2] is higher[2]:\n                    upper_bound = max(lower[1], higher[1])\n                    merged[-1] = (lower[0], upper_bound, lower[2])\n                else:\n                    if lower[1] > higher[1]:\n                        merged[-1] = lower\n                    else:\n                        merged[-1] = (lower[0], higher[1], higher[2])\n            else:\n                merged.append(higher)\n\n    return merged","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From 'annotation' column, we are extracting the starting index, ending index, entity label\n# So that we can convert the content in BILOU format\n\ndef get_entities(df):\n    \n    entities = []\n    \n    for i in range(len(df)):\n        entity = []\n    \n        for annot in df['annotation'][i]:\n            try:\n                ent = entity_dict[annot['label'][0]]\n                start = annot['points'][0]['start']\n                end = annot['points'][0]['end'] + 1\n                entity.append((start, end, ent))\n            except:\n                pass\n    \n        entity = mergeIntervals(entity)\n        entities.append(entity)\n    \n    return entities","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding a new column 'entities'\ndf['entities'] = get_entities(df)\ndf.head()","execution_count":94,"outputs":[{"output_type":"execute_result","execution_count":94,"data":{"text/plain":"                                             content  \\\n0  Abhishek Jha\\nApplication Development Associat...   \n1  Afreen Jamadar\\nActive member of IIIT Committe...   \n2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n\n                                          annotation  \\\n0  [{'label': ['Skills'], 'points': [{'start': 12...   \n1  [{'label': ['Email Address'], 'points': [{'sta...   \n2  [{'label': ['Skills'], 'points': [{'start': 37...   \n3  [{'label': ['Skills'], 'points': [{'start': 80...   \n4  [{'label': ['Degree'], 'points': [{'start': 20...   \n\n                                            entities  \n0  [(0, 12, NAME), (13, 46, DESIG), (49, 58, COMP...  \n1  [(0, 14, NAME), (62, 68, LOC), (104, 148, EMAI...  \n2  [(0, 21, NAME), (22, 31, LOC), (65, 117, EMAIL...  \n3  [(0, 12, NAME), (13, 51, DESIG), (54, 60, COMP...  \n4  [(0, 13, NAME), (14, 22, DESIG), (24, 41, COMP...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>annotation</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abhishek Jha\\nApplication Development Associat...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n      <td>[(0, 12, NAME), (13, 46, DESIG), (49, 58, COMP...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n      <td>[(0, 14, NAME), (62, 68, LOC), (104, 148, EMAI...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n      <td>[(0, 21, NAME), (22, 31, LOC), (65, 117, EMAIL...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n      <td>[(0, 12, NAME), (13, 51, DESIG), (54, 60, COMP...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n      <td>[(0, 13, NAME), (14, 22, DESIG), (24, 41, COMP...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_data(df):\n    tags = []\n    sentences = []\n\n    for i in range(len(df)):\n        text = df['content'][i]\n        entities = df['entities'][i]\n    \n        doc = nlp(text)\n    \n        tag = biluo_tags_from_offsets(doc, entities)\n        tmp = pd.DataFrame([list(doc), tag]).T\n        loc = []\n        for i in range(len(tmp)):\n            if tmp[0][i].text is '.' and tmp[1][i] is 'O':\n                loc.append(i)\n        loc.append(len(doc))\n    \n        last = 0\n        data = []\n        for pos in loc:\n            data.append([list(doc)[last:pos], tag[last:pos]])\n            last = pos\n    \n        for d in data:\n            tag = ['O' if t is '-' else t for t in d[1]]\n            if len(set(tag)) > 1:\n                sentences.append(d[0])\n                tags.append(tag)\n    \n    return sentences, tags","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences, tags = get_train_data(df)\nlen(sentences), len(tags)","execution_count":96,"outputs":[{"output_type":"execute_result","execution_count":96,"data":{"text/plain":"(781, 781)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag_vals = set(['X', '[CLS]', '[SEP]'])\nfor i in range(len(tags)):\n    tag_vals = tag_vals.union(tags[i])\ntag_vals","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"{'B-CLG',\n 'B-COMPANY',\n 'B-DEG',\n 'B-DESIG',\n 'B-EMAIL',\n 'B-GRADYEAR',\n 'B-LOC',\n 'B-NAME',\n 'B-SKILLS',\n 'B-YOE',\n 'I-CLG',\n 'I-COMPANY',\n 'I-DEG',\n 'I-DESIG',\n 'I-EMAIL',\n 'I-GRADYEAR',\n 'I-LOC',\n 'I-NAME',\n 'I-SKILLS',\n 'I-YOE',\n 'L-CLG',\n 'L-COMPANY',\n 'L-DEG',\n 'L-DESIG',\n 'L-EMAIL',\n 'L-GRADYEAR',\n 'L-LOC',\n 'L-NAME',\n 'L-SKILLS',\n 'L-YOE',\n 'O',\n 'U-CLG',\n 'U-COMPANY',\n 'U-DEG',\n 'U-DESIG',\n 'U-EMAIL',\n 'U-GRADYEAR',\n 'U-LOC',\n 'U-SKILLS',\n 'U-YOE',\n 'X',\n '[CLS]',\n '[SEP]'}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag2idx = {t: i for i, t in enumerate(tag_vals)}\ntag2idx","execution_count":98,"outputs":[{"output_type":"execute_result","execution_count":98,"data":{"text/plain":"{'U-EMAIL': 0,\n 'B-GRADYEAR': 1,\n 'I-YOE': 2,\n 'I-COMPANY': 3,\n '[SEP]': 4,\n 'I-DESIG': 5,\n 'L-LOC': 6,\n 'U-DEG': 7,\n 'L-GRADYEAR': 8,\n 'I-SKILLS': 9,\n 'L-DEG': 10,\n 'B-COMPANY': 11,\n 'I-LOC': 12,\n 'I-CLG': 13,\n 'L-EMAIL': 14,\n 'I-EMAIL': 15,\n 'L-CLG': 16,\n 'U-CLG': 17,\n 'U-SKILLS': 18,\n 'U-COMPANY': 19,\n 'B-DEG': 20,\n '[CLS]': 21,\n 'I-NAME': 22,\n 'B-LOC': 23,\n 'L-SKILLS': 24,\n 'U-GRADYEAR': 25,\n 'U-YOE': 26,\n 'L-NAME': 27,\n 'B-DESIG': 28,\n 'U-DESIG': 29,\n 'X': 30,\n 'O': 31,\n 'B-EMAIL': 32,\n 'I-DEG': 33,\n 'B-YOE': 34,\n 'L-COMPANY': 35,\n 'L-YOE': 36,\n 'B-CLG': 37,\n 'B-NAME': 38,\n 'I-GRADYEAR': 39,\n 'U-LOC': 40,\n 'L-DESIG': 41,\n 'B-SKILLS': 42}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx2tag = {tag2idx[key] : key for key in tag2idx.keys()}\nidx2tag","execution_count":99,"outputs":[{"output_type":"execute_result","execution_count":99,"data":{"text/plain":"{0: 'U-EMAIL',\n 1: 'B-GRADYEAR',\n 2: 'I-YOE',\n 3: 'I-COMPANY',\n 4: '[SEP]',\n 5: 'I-DESIG',\n 6: 'L-LOC',\n 7: 'U-DEG',\n 8: 'L-GRADYEAR',\n 9: 'I-SKILLS',\n 10: 'L-DEG',\n 11: 'B-COMPANY',\n 12: 'I-LOC',\n 13: 'I-CLG',\n 14: 'L-EMAIL',\n 15: 'I-EMAIL',\n 16: 'L-CLG',\n 17: 'U-CLG',\n 18: 'U-SKILLS',\n 19: 'U-COMPANY',\n 20: 'B-DEG',\n 21: '[CLS]',\n 22: 'I-NAME',\n 23: 'B-LOC',\n 24: 'L-SKILLS',\n 25: 'U-GRADYEAR',\n 26: 'U-YOE',\n 27: 'L-NAME',\n 28: 'B-DESIG',\n 29: 'U-DESIG',\n 30: 'X',\n 31: 'O',\n 32: 'B-EMAIL',\n 33: 'I-DEG',\n 34: 'B-YOE',\n 35: 'L-COMPANY',\n 36: 'L-YOE',\n 37: 'B-CLG',\n 38: 'B-NAME',\n 39: 'I-GRADYEAR',\n 40: 'U-LOC',\n 41: 'L-DESIG',\n 42: 'B-SKILLS'}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()","execution_count":100,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_tokenized_train_data(sentences, tags):\n\n    tokenized_texts = []\n    word_piece_labels = []\n\n    for word_list, label in zip(sentences, tags):\n    \n        # Add [CLS] at the front\n        temp_lable = ['[CLS]']\n        temp_token = ['[CLS]']\n    \n        for word, lab in zip(word_list, label):\n            token_list = tokenizer.tokenize(word.text)\n            for m, token in enumerate(token_list):\n                temp_token.append(token)\n                if m == 0:\n                    temp_lable.append(lab)\n                else:\n                    temp_lable.append('X')  \n                \n        # Add [SEP] at the end\n        temp_lable.append('[SEP]')\n        temp_token.append('[SEP]')\n    \n        tokenized_texts.append(temp_token)\n        word_piece_labels.append(temp_lable)\n    \n    return tokenized_texts, word_piece_labels","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenized_texts, word_piece_labels = get_tokenized_train_data(sentences, tags)","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tokenized_texts[0])\nprint(word_piece_labels[0])","execution_count":104,"outputs":[{"output_type":"stream","text":"['[CLS]', 'A', '##b', '##his', '##he', '##k', 'J', '##ha', 'Application', 'Development', 'Associate', '-', 'A', '##cc', '##ent', '##ure', 'Bengal', '##uru', ',', 'Karnataka', '-', 'Em', '##ail', 'me', 'on', 'Indeed', ':', 'indeed', '.', 'com', '/', 'r', '/', 'A', '##b', '##his', '##he', '##k', '-', 'J', '##ha', '/', '10', '##e', '##7', '##a', '##8', '##c', '##b', '##7', '##32', '##b', '##c', '##43', '##a', '•', 'To', 'work', 'for', 'an', 'organization', 'which', 'provides', 'me', 'the', 'opportunity', 'to', 'improve', 'my', 'skills', 'and', 'knowledge', 'for', 'my', 'individual', 'and', 'company', \"'\", 's', 'growth', 'in', 'best', 'possible', 'ways', '[SEP]']\n['[CLS]', 'B-NAME', 'X', 'X', 'X', 'X', 'L-NAME', 'X', 'B-DESIG', 'I-DESIG', 'L-DESIG', 'O', 'U-COMPANY', 'X', 'X', 'X', 'U-LOC', 'X', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'B-EMAIL', 'I-EMAIL', 'I-EMAIL', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 512\nbs = 4","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\nprint(len(input_ids[0]))\nprint(input_ids[0])","execution_count":106,"outputs":[{"output_type":"stream","text":"512\n[  101   138  1830 27516  4638  1377   147  2328 22491  3273  9666   118\n   138 19515  3452  3313  7756 12328   117 12247   118 18653 11922  1143\n  1113 10364   131  5750   119  3254   120   187   120   138  1830 27516\n  4638  1377   118   147  2328   120  1275  1162  1559  1161  1604  1665\n  1830  1559 17101  1830  1665 25631  1161   794  1706  1250  1111  1126\n  2369  1134  2790  1143  1103  3767  1106  4607  1139  4196  1105  3044\n  1111  1139  2510  1105  1419   112   188  3213  1107  1436  1936  3242\n   102     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels], maxlen=MAX_LEN, value=tag2idx[\"O\"], \n                     padding=\"post\", dtype=\"long\", truncating=\"post\")\nprint(len(tags[0]))\nprint(tags[0])","execution_count":107,"outputs":[{"output_type":"stream","text":"512\n[21 38 30 30 30 30 27 30 28  5 41 31 19 30 30 30 40 30 31 31 31 31 30 31\n 31 32 15 15 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30 30\n 30 30 30 30 30 30 30 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 30 31 31 31 31 31  4 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n 31 31 31 31 31 31 31 31]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\nprint(attention_masks[0])","execution_count":108,"outputs":[{"output_type":"stream","text":"[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks = train_test_split(input_ids, tags, attention_masks, random_state=2020, \n                                                                                 test_size=0.3)","execution_count":109,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_inputs = torch.tensor(tr_inputs)\nval_inputs = torch.tensor(val_inputs)\ntr_tags = torch.tensor(tr_tags)\nval_tags = torch.tensor(val_tags)\ntr_masks = torch.tensor(tr_masks)\nval_masks = torch.tensor(val_masks)","execution_count":110,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)","execution_count":111,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2idx))","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.cuda();","execution_count":113,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FULL_FINETUNING = True\nif FULL_FINETUNING:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters()) \n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\noptimizer = Adam(optimizer_grouped_parameters, lr=3e-5)","execution_count":114,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 10\nmax_grad_norm = 1.0\n\nfor _ in trange(epochs, desc=\"Epoch\"):\n    # TRAIN loop\n    model.train()\n    tr_loss = 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    for step, batch in enumerate(train_dataloader):\n        # add batch to gpu\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        # forward pass\n        loss = model(b_input_ids, token_type_ids=None,\n                     attention_mask=b_input_mask, labels=b_labels)\n        # backward pass\n        loss.backward()\n        # track train loss\n        tr_loss += loss.item()\n        nb_tr_examples += b_input_ids.size(0)\n        nb_tr_steps += 1\n        # gradient clipping\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n        # update parameters\n        optimizer.step()\n        model.zero_grad()\n    # print train loss per epoch\n    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))","execution_count":115,"outputs":[{"output_type":"stream","text":"Epoch:  10%|█         | 1/10 [00:40<06:07, 40.83s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.7855978280740933\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  20%|██        | 2/10 [01:21<05:26, 40.79s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.36433469335528185\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  30%|███       | 3/10 [02:02<04:45, 40.77s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.24948525708848543\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  40%|████      | 4/10 [02:42<04:04, 40.74s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.1869373892563103\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  50%|█████     | 5/10 [03:23<03:23, 40.71s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.1422624479381055\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  60%|██████    | 6/10 [04:04<02:42, 40.70s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.11470974036866297\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  70%|███████   | 7/10 [04:44<02:02, 40.69s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.08099931645730551\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  80%|████████  | 8/10 [05:25<01:21, 40.62s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.06329664413946388\n","name":"stdout"},{"output_type":"stream","text":"\rEpoch:  90%|█████████ | 9/10 [06:05<00:40, 40.61s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.05557718787709401\n","name":"stdout"},{"output_type":"stream","text":"Epoch: 100%|██████████| 10/10 [06:46<00:00, 40.65s/it]","name":"stderr"},{"output_type":"stream","text":"Train loss: 0.04936946616983925\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\n\ny_true = []\ny_pred = []\neval_loss, eval_accuracy = 0, 0\nnb_eval_steps, nb_eval_examples = 0, 0\n\nfor batch in valid_dataloader:\n    batch = tuple(t.to(device) for t in batch)\n    input_ids, input_mask, label_ids = batch\n\n    with torch.no_grad():\n        logits = model(input_ids, token_type_ids=None, attention_mask=input_mask,)\n\n    logits = logits.detach().cpu().numpy()\n    logits = [list(p) for p in np.argmax(logits, axis=2)]\n    \n    label_ids = label_ids.to('cpu').numpy()\n    input_mask = input_mask.to('cpu').numpy()\n    \n    for i,mask in enumerate(input_mask):\n        temp_1 = [] # Real one\n        temp_2 = [] # Predict one\n        \n        for j, m in enumerate(mask):\n            # Mark=0, meaning its a pad word, dont compare\n            if m:\n                if idx2tag[label_ids[i][j]] != \"X\" and idx2tag[label_ids[i][j]] != \"[CLS]\" and idx2tag[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n                    temp_1.append(idx2tag[label_ids[i][j]])\n                    temp_2.append(idx2tag[logits[i][j]])\n            else:\n                break\n        \n            \n        y_true.append(temp_1)\n        y_pred.append(temp_2)\n    \nprint(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\nprint(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n\nprint(classification_report(y_true, y_pred,digits=4))","execution_count":116,"outputs":[{"output_type":"stream","text":"f1 socre: 0.498943\nAccuracy score: 0.849793\n           precision    recall  f1-score   support\n\n  COMPANY     0.5792    0.6127    0.5955       173\n      LOC     0.6752    0.6752    0.6752       117\n    EMAIL     0.4364    0.6857    0.5333        35\n GRADYEAR     0.5111    0.4107    0.4554        56\n     NAME     0.9138    0.9138    0.9138        58\n    DESIG     0.5503    0.6891    0.6119       119\n   SKILLS     0.1371    0.2368    0.1736       114\n      DEG     0.5054    0.6184    0.5562        76\n      CLG     0.3563    0.4697    0.4052        66\n      YOE     0.0000    0.0000    0.0000        10\n\nmicro avg     0.4419    0.5728    0.4989       824\nmacro avg     0.5087    0.5728    0.5350       824\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}